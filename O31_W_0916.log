DataSet:Office-31_Alex\Data_office31 
Target Domain:webcam
Yt_new [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1
  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2  2
  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3
  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4
  4  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6
  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7
  7  7  7  7  7  7  7  7  7  7  7  7  8  8  8  8  9  9  9  9  9  9  9  9
  9  9  9  9  9  9  9  9  9  9  9 21 21 21 21 21 21 21 21 22 22 22 22 22
 22 22 22 22 22 23 23 24 24 24 24 24 24 25 25 27 27 28 28 29 29 30 30 30
 30 30 30 30  0  0  0  0  0  0  0  0  3  5  5  5  7  7  7  8  8  8  8  8
  8  8  8  8  8  8  8  8  8  8  8  8 21 21 21 21 21 21 21 21 21 21 21 21
 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 23 23 23 23
 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 24 24 24
 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24
 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 26 26 26 26 26 26 26 26
 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 27 27 27 27 27 27 27
 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 28 28 28
 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 29 29 29 29 29
 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 30 30 30 30 30 30 30 30
 30 30 30 30 30 30]
Yt_pseudo [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1
  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2  2
  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3
  3  8  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4
  4  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6
  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7
  7  7  7  7  7  7  7  7  7  7  7  7  9  9  9  8  9  9  9  9  9  9  9  9
  9  9  9  9  9  9  9  9  0  9  9  9  9  9  9  9  9  9  9  8  8  8  5  8
  8  8  8  6  8  0  0  9  9  9  9  9  0  7  7  7  7  3  3  0  4  9  9  9
  8  9  9  9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10]
use this
pseudo Xtk: [0.84255319]
pseudo Xtu: [0.83665339]
all acc [0.83950617]
Optimizing...
Iteration    Cost                       Gradient norm     
---------    -----------------------    --------------    
 1           +7.4797174989499116e-02    2.72768194e-02    
 2           +5.7339134517231827e-02    1.46137543e-02    
 3           +5.6344678737531018e-02    3.15979376e-02    
 4           +5.2712416684477237e-02    2.61776974e-02    
 5           +4.5424829074387496e-02    1.65475461e-02    
 6           +4.4650256982621261e-02    4.13877505e-02    
 7           +4.1642204502113422e-02    3.89391710e-02    
 8           +3.1694184141905168e-02    2.51486797e-02    
 9           +2.8574606130382652e-02    2.54226839e-02    
10           +2.2750577800478400e-02    1.20130849e-02    
11           +2.2715130066642608e-02    3.08259838e-02    
12           +2.2573846781739126e-02    3.06017729e-02    
13           +2.2017017237137448e-02    2.96876079e-02    
14           +1.9934459664737059e-02    2.57594850e-02    
15           +1.4734939074471320e-02    8.40421925e-03    
16           +1.2874972720779088e-02    1.72017274e-02    
17           +1.1506241307199794e-02    1.43500479e-02    
18           +1.0710106600722025e-02    1.36908892e-02    
19           +9.3021250728897442e-03    5.66572750e-03    
20           +8.8318181434152709e-03    8.93866866e-03    
21           +8.3273629521394277e-03    7.26716535e-03    
22           +7.8784476472648635e-03    4.44704182e-03    
23           +7.6683783903430669e-03    7.67257194e-03    
24           +7.2183103689351658e-03    2.90665818e-03    
25           +6.6287591350258079e-03    9.71996469e-03    
26           +6.4493116417401186e-03    8.76343180e-03    
27           +5.9797667606535931e-03    2.88305601e-03    
28           +5.9339939711513523e-03    3.24126600e-03    
29           +5.8503491481955994e-03    1.72283200e-03    
30           +5.8101572448205907e-03    3.61110686e-03    
31           +5.7157728839727362e-03    1.31140831e-03    
32           +5.4261165498354913e-03    2.82124050e-03    
33           +5.3682873311855506e-03    1.52352345e-03    
34           +5.3638902569115299e-03    3.25586470e-03    
35           +5.3473139469562003e-03    2.88414256e-03    
36           +5.2987575827050382e-03    1.47261530e-03    
37           +5.2830970396946508e-03    2.73783423e-03    
38           +5.2377931754712392e-03    1.37257728e-03    
39           +5.2185321425888276e-03    2.64793232e-03    
40           +5.1694284481909047e-03    1.09063647e-03    
41           +5.1080760447230755e-03    4.29071682e-03    
42           +4.9828384074448451e-03    1.01057708e-03    
43           +4.7426461114055130e-03    6.03924073e-03    
44           +4.5024433564209154e-03    9.68304378e-04    
45           +4.4686715515596109e-03    7.78543662e-03    
46           +4.3445200402771889e-03    6.52677832e-03    
47           +4.0580332594166713e-03    1.45517604e-03    
48           +4.0284943025903353e-03    1.47689090e-03    
49           +4.0034706669289655e-03    1.38673702e-03    
50           +3.9816272562545052e-03    1.36583912e-03    
Terminated - max iterations reached after 158.42 seconds.

ms:978,mt:486
lu: [0. 1. 2.] lc [154 824 486]
current_index 978
[[0.0805823 0.        0.        ... 0.        0.        0.       ]
 [0.        0.0805823 0.        ... 0.        0.        0.       ]
 [0.        0.        0.0805823 ... 0.        0.        0.       ]
 ...
 [0.        0.        0.        ... 0.        0.        0.       ]
 [0.        0.        0.        ... 0.        0.        0.       ]
 [0.        0.        0.        ... 0.        0.        0.       ]]
loss is -4.70 | known_loss is 6.84 | unknown_loss is -12.75 ( 1.20 + 0.27 - 14.22 )
use this

Iteration :1
pseudo Xtk : [0.92340426]
pseudo Xtu: [0.7689243]
all acc [0.8436214]
Optimizing...
Iteration    Cost                       Gradient norm     
---------    -----------------------    --------------    
 1           +7.4612661504689148e-02    2.90928947e-02    
 2           +5.5341283260902152e-02    1.62477127e-02    
 3           +5.1884224842984494e-02    3.00054231e-02    
 4           +4.3526731990273015e-02    1.30765027e-02    
 5           +2.9720658533873179e-02    2.72025041e-02    
 6           +2.1215190803417938e-02    2.31682051e-02    
 7           +1.8052431125008983e-02    2.27638145e-02    
 8           +1.4101200762504318e-02    1.60882110e-02    
 9           +1.2526914236595132e-02    1.79416390e-02    
10           +9.8873994056276615e-03    9.96414519e-03    
11           +9.8774727944861418e-03    2.09064603e-02    
12           +9.8378795080735770e-03    2.07871530e-02    
13           +9.6813321678843600e-03    2.03073742e-02    
14           +9.0853480963333233e-03    1.83495153e-02    
15           +7.2518379095054541e-03    1.01807057e-02    
16           +7.0095114086814458e-03    1.47408041e-02    
17           +6.1789989800886680e-03    1.05827010e-02    
18           +5.8118012959029741e-03    1.24972234e-02    
19           +4.8003597574712842e-03    5.48266909e-03    
20           +4.3170449551983570e-03    6.57732664e-03    
21           +3.9058835177865348e-03    5.25967809e-03    
22           +3.6047022116831862e-03    5.95493978e-03    
23           +3.5240009827242069e-03    8.61912677e-03    
24           +3.2489801862407575e-03    6.12910399e-03    
25           +3.1248346896886048e-03    7.32326059e-03    
26           +2.7821683576669809e-03    3.25978210e-03    
27           +2.7522774520325477e-03    8.12916937e-03    
28           +2.6404618786282086e-03    7.08068759e-03    
29           +2.3338362054214912e-03    2.96909888e-03    
30           +2.2360784600203854e-03    4.04472351e-03    
31           +2.1258343449543915e-03    3.57907728e-03    
32           +2.1211234925861966e-03    5.43175131e-03    
33           +2.1026987016865561e-03    5.19066688e-03    
34           +2.0359552763213884e-03    4.22295520e-03    
35           +1.8994041848741094e-03    1.80564215e-03    
36           +1.7645378775983378e-03    3.97095979e-03    
37           +1.6524788383442957e-03    1.91562454e-03    
38           +1.6027036613890377e-03    2.27797363e-03    
39           +1.5988598404914622e-03    3.94187988e-03    
40           +1.5840207019057750e-03    3.66822219e-03    
41           +1.5337279313361041e-03    2.58258648e-03    
42           +1.5125378704661241e-03    3.34729811e-03    
43           +1.4495513015992945e-03    1.76849726e-03    
44           +1.4241027976105158e-03    2.99073816e-03    
45           +1.3607627062710570e-03    1.23633974e-03    
46           +1.1986055550776697e-03    3.40148941e-03    
47           +1.1974845488853525e-03    4.08186814e-03    
48           +1.1930449944910215e-03    4.00098487e-03    
49           +1.1760107660343522e-03    3.67593985e-03    
50           +1.1203322393442683e-03    2.36783011e-03    
Terminated - max iterations reached after 181.75 seconds.

ms:978,mt:486
lu: [0. 1. 2.] lc [154 824 486]
current_index 978
[[0.0805823 0.        0.        ... 0.        0.        0.       ]
 [0.        0.0805823 0.        ... 0.        0.        0.       ]
 [0.        0.        0.0805823 ... 0.        0.        0.       ]
 ...
 [0.        0.        0.        ... 0.        0.        0.       ]
 [0.        0.        0.        ... 0.        0.        0.       ]
 [0.        0.        0.        ... 0.        0.        0.       ]]
loss is -4.91 | known_loss is 7.36 | unknown_loss is -13.43 ( 1.25 + 0.18 - 14.86 )
use this

Iteration :2
pseudo Xtk : [0.93191489]
pseudo Xtu: [0.77290837]
all acc [0.84979424]
Optimizing...
Iteration    Cost                       Gradient norm     
---------    -----------------------    --------------    
 1           +7.6163148508601175e-02    2.90974131e-02    
 2           +5.6378736577737065e-02    1.64422061e-02    
 3           +5.1210350401082128e-02    2.80910186e-02    
 4           +4.4169448929364030e-02    2.20895506e-02    
 5           +3.8319982966334543e-02    2.30943527e-02    
 6           +3.4960180315236400e-02    3.34865032e-02    
 7           +2.5979635856296035e-02    1.32118256e-02    
 8           +2.2778169582606811e-02    2.19816512e-02    
 9           +1.9516868717068370e-02    1.99025345e-02    
10           +1.8251482985317313e-02    2.50949452e-02    
11           +1.4419966922391447e-02    1.35677110e-02    
12           +1.3649825058904330e-02    2.24246925e-02    
13           +1.1154770132144165e-02    1.41201796e-02    
14           +9.5523684838889622e-03    1.28493453e-02    
15           +8.0362031056764316e-03    8.47896722e-03    
16           +7.0790023613065411e-03    1.32636002e-02    
17           +5.9027677945151513e-03    9.72948727e-03    
18           +5.1935889382010991e-03    9.08734796e-03    
19           +5.1313816112179556e-03    1.35423367e-02    
20           +4.8940616076422749e-03    1.22902178e-02    
21           +4.1473229991157989e-03    7.26047468e-03    
22           +3.7886498373209676e-03    8.22523505e-03    
23           +3.3033906273196578e-03    6.03986569e-03    
24           +3.0122730545727450e-03    6.29957484e-03    
25           +2.8462826359081372e-03    7.69092660e-03    
26           +2.4327518005571314e-03    3.01315895e-03    
27           +2.0728061748847004e-03    1.10471131e-02    
28           +1.2852526446400780e-03    1.79301923e-03    
29           +1.1896116533676171e-03    3.35660495e-03    
30           +1.1026649189362914e-03    1.77267425e-03    
31           +1.0667188797792715e-03    3.81538315e-03    
32           +9.7261141564608522e-04    1.52924467e-03    
33           +9.3979254446452387e-04    4.30164727e-03    
34           +8.4255642401620534e-04    2.17319676e-03    
35           +7.9999348821990779e-04    1.66868003e-03    
36           +7.6493471466898555e-04    2.04142292e-03    
37           +7.5038596486098896e-04    3.03970929e-03    
38           +7.0471179645470450e-04    1.81227103e-03    
39           +6.7391189899668191e-04    2.05567047e-03    
40           +6.5048597431527355e-04    2.54239571e-03    
41           +6.0057692033899102e-04    1.17667268e-03    
42           +5.1888851879233755e-04    4.01849876e-03    
43           +4.3896964636691571e-04    2.63811010e-03    
44           +4.0310120544240213e-04    2.29579973e-03    
45           +3.8398070852041499e-04    2.64158178e-03    
46           +3.3595904778893626e-04    1.07931442e-03    
47           +2.3784588651620808e-04    3.67600215e-03    
48           +1.4757752604332985e-04    1.17130359e-03    
49           +1.1974687270743800e-04    2.75590503e-03    
50           +6.5533175957366296e-05    1.10249060e-03    
Terminated - max iterations reached after 183.90 seconds.

ms:978,mt:486
lu: [0. 1. 2.] lc [154 824 486]
current_index 978
[[0.0805823 0.        0.        ... 0.        0.        0.       ]
 [0.        0.0805823 0.        ... 0.        0.        0.       ]
 [0.        0.        0.0805823 ... 0.        0.        0.       ]
 ...
 [0.        0.        0.        ... 0.        0.        0.       ]
 [0.        0.        0.        ... 0.        0.        0.       ]
 [0.        0.        0.        ... 0.        0.        0.       ]]
loss is -4.91 | known_loss is 7.37 | unknown_loss is -13.43 ( 1.29 + 0.16 - 14.88 )
use this

Iteration :3
pseudo Xtk : [0.94042553]
pseudo Xtu: [0.77689243]
all acc [0.85596708]
Optimizing...
Iteration    Cost                       Gradient norm     
---------    -----------------------    --------------    
 1           +7.6905606907142099e-02    2.91413669e-02    
 2           +5.6823322275528998e-02    1.64724180e-02    
 3           +5.0903475517089625e-02    2.72052899e-02    
 4           +4.5689674943431235e-02    2.83350019e-02    
 5           +3.7998664173724883e-02    2.38586056e-02    
 6           +3.1210149905430473e-02    2.07991899e-02    
 7           +2.7117110741262440e-02    2.16357782e-02    
 8           +2.5890678198175809e-02    2.81576211e-02    
 9           +2.1836232532770561e-02    1.86400305e-02    
10           +1.8547371052467732e-02    1.48499717e-02    
11           +1.6042636385956932e-02    1.63296178e-02    
12           +1.5456489686675789e-02    2.46675366e-02    
13           +1.3386399258224824e-02    1.89410193e-02    
14           +1.0906837353662269e-02    1.45710560e-02    
15           +9.1704114973896189e-03    1.20167763e-02    
16           +7.8319512891034115e-03    1.05343290e-02    
17           +6.7351930002410576e-03    9.37727591e-03    
18           +5.8374855858156494e-03    8.74054215e-03    
19           +5.0674881199017641e-03    7.62334323e-03    
20           +4.4527441947237456e-03    7.68803763e-03    
21           +3.8804028594148221e-03    5.81470792e-03    
22           +3.4615679536424970e-03    7.56575368e-03    
23           +3.2397610255698872e-03    9.17390852e-03    
24           +2.6675430835891856e-03    3.68531364e-03    
25           +2.2590538289328777e-03    8.70927854e-03    
26           +1.8984051424204562e-03    6.31358192e-03    C:\Users\10913\AppData\Local\Programs\Python\Python37\lib\site-packages\autograd\tracer.py:14: UserWarning: Output seems independent of input.
  warnings.warn("Output seems independent of input.")

27           +1.6207450476009022e-03    3.42169394e-03    
28           +1.4900551393000061e-03    3.12210877e-03    
29           +1.3765918565036284e-03    3.25925470e-03    
30           +1.2692176756234907e-03    2.63761559e-03    
31           +1.1788604672582359e-03    3.17430840e-03    
32           +1.1682921251825462e-03    5.11547995e-03    
33           +1.1284340708945795e-03    4.53512087e-03    
34           +1.0114402540486456e-03    2.32086150e-03    
35           +9.7805020022145861e-04    4.26406391e-03    
36           +8.7849393231076434e-04    2.24845183e-03    
37           +8.5063603047297320e-04    3.81726920e-03    
38           +7.6840278898249181e-04    1.98433164e-03    
39           +7.3896156389219314e-04    3.49348641e-03    
40           +6.5984034619770426e-04    1.52762767e-03    
41           +6.0709182079277113e-04    3.50340591e-03    
42           +5.2293461008412478e-04    1.73149195e-03    
43           +4.8647582687522117e-04    1.93980103e-03    
44           +4.8121332587358623e-04    3.40808539e-03    
45           +4.6150894511631790e-04    2.97631921e-03    
46           +4.0646458827175991e-04    1.40203439e-03    
47           +3.7604882047936883e-04    2.97350457e-03    
48           +3.1191915456951769e-04    1.14922703e-03    
49           +1.8666137103218183e-04    4.23637064e-03    
50           +6.8011771970688528e-05    1.14125219e-03    
Terminated - max iterations reached after 200.85 seconds.

ms:978,mt:486
lu: [0. 1. 2.] lc [154 824 486]
current_index 978
[[0.0805823 0.        0.        ... 0.        0.        0.       ]
 [0.        0.0805823 0.        ... 0.        0.        0.       ]
 [0.        0.        0.0805823 ... 0.        0.        0.       ]
 ...
 [0.        0.        0.        ... 0.        0.        0.       ]
 [0.        0.        0.        ... 0.        0.        0.       ]
 [0.        0.        0.        ... 0.        0.        0.       ]]
loss is -4.92 | known_loss is 7.37 | unknown_loss is -13.44 ( 1.29 + 0.16 - 14.89 )
use this

Iteration :4
pseudo Xtk : [0.94468085]
pseudo Xtu: [0.77689243]
all acc [0.85802469]
Optimizing...
Iteration    Cost                       Gradient norm     
---------    -----------------------    --------------    
 1           +7.7588711864557514e-02    2.92857601e-02    
 2           +5.7233588902192434e-02    1.65883518e-02    
 3           +5.1026679464895253e-02    2.69131816e-02    
 4           +4.6668022318774982e-02    3.07534384e-02    
 5           +3.7333638142626580e-02    1.70424825e-02    
 6           +2.8829176610525309e-02    2.53756289e-02    
 7           +2.4714246965065634e-02    2.18772298e-02    
 8           +2.3591427048714753e-02    2.83926073e-02    
 9           +1.9815722629180410e-02    1.95142837e-02    
10           +1.6333700953119923e-02    1.24599787e-02    
11           +1.4278758537731751e-02    2.02581375e-02    
12           +1.1152871671480380e-02    1.22555228e-02    
13           +1.0789037427199943e-02    2.10436286e-02    
14           +9.4875538067276111e-03    1.66207519e-02    
15           +7.4252249942217130e-03    9.32389265e-03    
16           +6.4156414378491178e-03    8.26513187e-03    
17           +5.6064798559940510e-03    9.31410799e-03    
18           +4.8058490843732038e-03    6.11843011e-03    
19           +4.2069553236978585e-03    9.49799783e-03    
20           +3.8289472012813519e-03    1.00182219e-02    
21           +3.0814641403298371e-03    4.10877668e-03    
22           +2.7077541602071875e-03    1.08145591e-02    
23           +1.9190791286312070e-03    2.64193163e-03    
24           +8.6390053357510155e-04    4.60081826e-03    
25           +7.4774723476722649e-04    4.39739839e-03    
26           +6.5177150510553616e-04    4.05085483e-03    
27           +5.6652760671171976e-04    3.58910067e-03    
28           +5.2006973037777016e-04    3.90553190e-03    
29           +4.1287590976701871e-04    1.41849947e-03    
30           +1.0474411525063232e-04    1.65523456e-03    
31           +7.9613783501297775e-05    1.89519490e-03    
32           +5.8671303261537133e-05    2.22717952e-03    
33           +1.9848755407281260e-05    1.23806029e-03    
Traceback (most recent call last):
  File "C:\Users\10913\AppData\Local\Programs\Python\Python37\lib\site-packages\autograd\core.py", line 233, in vspace
    return VSpace.mappings[type(value)](value)
KeyError: <class 'int'>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "MSODAv1.py", line 407, in <module>
    W = cost_manifold(Ws, Wt,l, Cs, Xs_all, ys_all, Xt_new, Yt_pseudo, 50, 100).point
  File "MSODAv1.py", line 256, in cost_manifold
    W = optimizer.run(problem, initial_point=[Ws[:, :dimension], Wt[:, :dimension]])
  File "C:\Users\10913\AppData\Local\Programs\Python\Python37\lib\site-packages\pymanopt\optimizers\steepest_descent.py", line 96, in run
    grad = gradient(x)
  File "C:\Users\10913\AppData\Local\Programs\Python\Python37\lib\site-packages\pymanopt\core\problem.py", line 257, in riemannian_gradient
    point, self.euclidean_gradient(point)
  File "C:\Users\10913\AppData\Local\Programs\Python\Python37\lib\site-packages\pymanopt\core\problem.py", line 149, in wrapper
    return_values = function(*args, **kwargs)
  File "C:\Users\10913\AppData\Local\Programs\Python\Python37\lib\site-packages\pymanopt\core\problem.py", line 175, in wrapper
    return function(*self._flatten_arguments(point, point_layout))
  File "C:\Users\10913\AppData\Local\Programs\Python\Python37\lib\site-packages\pymanopt\autodiff\backends\_autograd.py", line 18, in wrapper
    return list(map(np.conj, function(*args, **kwargs)))
  File "C:\Users\10913\AppData\Local\Programs\Python\Python37\lib\site-packages\autograd\wrap_util.py", line 20, in nary_f
    return unary_operator(unary_f, x, *nary_op_args, **nary_op_kwargs)
  File "C:\Users\10913\AppData\Local\Programs\Python\Python37\lib\site-packages\autograd\differential_operators.py", line 29, in grad
    if not vspace(ans).size == 1:
  File "C:\Users\10913\AppData\Local\Programs\Python\Python37\lib\site-packages\autograd\core.py", line 240, in vspace
    value, type(value), VSpace.mappings.keys()))
TypeError: Can't find vector space for value 0 of type <class 'int'>. Valid types are dict_keys([<class 'autograd.core.SparseObject'>, <class 'list'>, <class 'tuple'>, <class 'dict'>, <class 'numpy.ndarray'>, <class 'float'>, <class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>, <class 'complex'>, <class 'numpy.complex64'>, <class 'numpy.complex128'>])
