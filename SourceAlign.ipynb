{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import scipy.linalg as la\n",
    "from sklearn.svm import SVC\n",
    "# from JDIP import JDIP\n",
    "# from MSJDIP import MSJDIP\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import scale,LabelEncoder\n",
    "from os import path as osp\n",
    "import autograd.numpy as anp\n",
    "import autograd.numpy.linalg as alina\n",
    "import pymanopt as pm\n",
    "import pymanopt.manifolds as manifolds\n",
    "import pymanopt.optimizers as optimizers\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import autograd.numpy as anp\n",
    "import autograd.numpy.linalg as alina\n",
    "import numpy as np\n",
    "import numpy.linalg as nlina\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import scale\n",
    "import sys\n",
    "\n",
    "\n",
    "def readDataMS(root,scs,tg,Cs_end,Cu_start,fn='fea',postfix=''): \n",
    "    '''\n",
    "    root: 数据集路径,eg 'OSDA-2/Office-31_Alex/Data_office31'\n",
    "    scs: List of source domain name, eg ['dslr','webcam']\n",
    "    tg: name of target domain name, eg 'amazon'\n",
    "    Cs_end: Known end\n",
    "    Cu_start: Unknown start\n",
    "    fn: 在mat文件中feature列名 \n",
    "    postfix: 每个数据集文件的后缀名\n",
    "\n",
    "    return: \n",
    "        Xs: List of numpy array\n",
    "        Xt: Numpy array\n",
    "        l: numpy array of label of the sample\n",
    "\n",
    "    '''\n",
    "    Xs,ys,l=[],[],[]\n",
    "    li=0\n",
    "    for sc in scs:\n",
    "        data = sio.loadmat(osp.join(root ,sc + postfix+'.mat'))# source domain \n",
    "        Xsi,ysi = data[fn].astype(np.float64),data['labels'].ravel()\n",
    "        ysi = LabelEncoder().fit(ysi).transform(ysi).astype(np.float64)\n",
    "        Xsi = Xsi / la.norm(Xsi,axis=1,keepdims=True)\n",
    "        Xsn=Xsi[ysi[:]<Cs_end,:]\n",
    "        ysn=ysi[ysi[:]<Cs_end]#筛选出已知类\n",
    "        Xs.append(Xsn)\n",
    "        ys.append(ysn)\n",
    "        l=np.hstack((np.array(l),np.full((Xsn.shape[0],),li)))\n",
    "        li+=1\n",
    "\n",
    "    data = sio.loadmat(osp.join(root , tg + postfix+'.mat'))# target domain \n",
    "    Xt,yt = data[fn].astype(np.float64),data['labels'].ravel()\n",
    "    yt = LabelEncoder().fit(yt).transform(yt).astype(np.float64)\n",
    "    C=len(np.unique(yt))\n",
    "    # index_unknwon=yt[yt[:]>Cs_end and yt[:]<Cu_start]\n",
    "    Xt=np.vstack((Xt[yt[:]<Cs_end,:],Xt[yt[:]>=Cu_start,:]))#筛选已知类和未知类\n",
    "    yt=np.hstack((yt[yt[:]<Cs_end],yt[yt[:]>=Cu_start]))\n",
    "\n",
    "    l=np.hstack((np.array(l),np.full((Xt.shape[0],),li)))\n",
    "    \n",
    "    Xt = Xt / la.norm(Xt,axis=1,keepdims=True)\n",
    "\n",
    "    Cs = Cs_end\n",
    "    Cu = C - Cu_start\n",
    "\n",
    "    return Xs,ys,Xt,yt,l,Cs,Cu\n",
    "\n",
    "def compute_one_unknown(Ytu, Ytu_pseudo, Cs):\n",
    "    \"\"\"\n",
    "    :param Ytu: 实际未知类的标签,全部为未知类\n",
    "    :param Ytu_pseudo: 实际未知类的伪标签,可能混合已知类\n",
    "    :param Cs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 计算预测未知类中真实未知类的准确率\n",
    "    one_unknown = Ytu_pseudo[Ytu_pseudo >= Cs].shape[0] / Ytu.shape[0]\n",
    "    # Ytu2=Ytu.copy()\n",
    "    # Ytu2[Ytu2>=Cs]=1\n",
    "    # one_unknown = (Ytu_pseudo[Ytu2 == Cs]==Cs).sum() / Ytu.shape[0]\n",
    "\n",
    "    return one_unknown\n",
    "\n",
    "def compute_acc_known(Ytk, Ytk_pseudo, Cs):\n",
    "    \"\"\"\n",
    "    :param Ytk: 实际已知类的标签\n",
    "    :param Ytk_pseudo: 实际已知类的伪标签\n",
    "    :param Cs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 计算已知类的平均准确率\n",
    "    acc_known = 0\n",
    "    for c in range(Cs):  # 计算已知类的分类准确率\n",
    "        known_i = np.sum(Ytk_pseudo[Ytk == c] == Ytk[Ytk == c]) / Ytk[Ytk == c].shape[0]\n",
    "        acc_known = acc_known + known_i\n",
    "\n",
    "    acc_known = acc_known / Cs\n",
    "\n",
    "    return acc_known\n",
    "\n",
    "# def compute_acc(Y, Y_pseudo, Cs):\n",
    "#     acc_known = 0\n",
    "#     acc_unknown = 0\n",
    "#     known_i = 0\n",
    "#     unknown_i = 0\n",
    "#     mtk = Y[Y < Cs].shape\n",
    "#     mtu = Y[Y >= Cs].shape\n",
    "#     mt = Y.shape\n",
    "#     # 计算已知类的分类准确率\n",
    "#     for c in range(Cs):  \n",
    "#         known_i += np.sum(Y_pseudo[Y == c] == Y[Y == c]) \n",
    "#     acc_known = known_i/mtk\n",
    "#     # 计算未知类的分类准确率\n",
    "#     unknown_i = np.sum(Y_pseudo[Y >= Cs ] == Cs)\n",
    "#     acc_unknown = unknown_i/mtu\n",
    "#     # 计算总体分类准确率\n",
    "#     acc = (unknown_i+known_i)/mt\n",
    "#     print('use this')\n",
    "#     return acc,acc_unknown,acc_known\n",
    "\n",
    "def compute_acc(Y, Y_pseudo, Cs):\n",
    "    acc_os_all = 0\n",
    "    acc_os_k = 0\n",
    "    os = 0\n",
    "    os_1 = 0 \n",
    "    # print(Y)\n",
    "    # print(Y_pseudo)\n",
    "    # 计算已知类的分类准确率\n",
    "    for c in range(Cs):\n",
    "        os_1 = np.sum(Y_pseudo[Y == c] == Y[Y == c]) /Y[Y == c].shape\n",
    "        acc_os_k += os_1\n",
    "    acc_os_k = acc_os_k/Cs\n",
    "    print(acc_os_k)\n",
    "    # 计算未知类的分类准确率\n",
    "    for c in range(Cs):\n",
    "        os = np.sum(Y_pseudo[Y == c] == Y[Y == c]) /Y[Y == c].shape\n",
    "        acc_os_all += os \n",
    "    os_unk = np.sum(Y_pseudo[Y >= Cs ] == Cs)/Y[Y >= Cs ].shape\n",
    "    acc_os_all += os_unk\n",
    "    acc_os_all = acc_os_all/(Cs+1)\n",
    "    HOS=2*(acc_os_k*os_unk)/(acc_os_k+os_unk)\n",
    "    return acc_os_all,os_unk,acc_os_k,HOS\n",
    "\n",
    "def cla_Svc(Xs, Xt, Ys):\n",
    "    # 2.SVM分类模型\n",
    "    model_cla = LinearSVC(dual=False)  # dual决定无法收敛时取消默认1000的迭代次数\n",
    "    model_cla.fit(Xs, Ys)\n",
    "    conf_matrix = model_cla.decision_function(Xt)\n",
    "    conf_label = conf_matrix.argmax(axis=1)  # 每个样本最大置信度的索引,即类\n",
    "    conf_vec = np.max(conf_matrix, axis=1)  # 每个样本最大置信度\n",
    "\n",
    "    return conf_label, conf_vec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cost_manifold(Ws,Wt,l, Cs, Xs, Ys ,Xt,Yt, Maxiter, dimension, truncated_param=1e-8):\n",
    "    # FX=np.vstack(FX,Xt)\n",
    "    # y=np.vstack(ys,Yt_pseudo)\n",
    "    # print(Ws,Wt,l,Cs,Xs)\n",
    "    dim = Xs.shape[1]\n",
    "    manifold = manifolds.Product([manifolds.Stiefel(dim, dimension), manifolds.Stiefel(dim, dimension)])\n",
    "\n",
    "    # 2.切分Xt已知类和未知类\n",
    "    Xtk = Xt[Yt < Cs, :]\n",
    "    Ytk = Yt[Yt < Cs]\n",
    "    # print(Ys.shape,Yt.shape)\n",
    "    lk=l[np.hstack((Ys,Yt))<Cs]\n",
    "    # 融合源域和目标域\n",
    "    Yk_all=np.hstack((Ys,Ytk))\n",
    "    Xk_all=np.vstack((Xs,Xtk))\n",
    "\n",
    "    @pm.function.autograd(manifold)\n",
    "    def cost(Ws,Wt):\n",
    "        # 1.更新Xs\n",
    "        Xs_W = anp.dot(Xs, Ws)\n",
    "        Xtk_W = anp.dot(Xtk, Wt)\n",
    "        # print(lk,Ytk)\n",
    "        X_all_W=anp.vstack((Xs_W,Xtk_W))\n",
    "\n",
    "        # # print(type(Xall_W[0]),type(Xall_W))\n",
    "        known_dist = pairwise_distances(Xk_all,Xk_all, 'euclidean')**2\n",
    "        known_sigma = np.median(known_dist[known_dist != 0])\n",
    "        # # print(\"sigma\",known_sigma)\n",
    "\n",
    "        known_rcs=RMI_np(X_all_W,Yk_all,lk,sigma=known_sigma,alpha=0)\n",
    "        # 没有*2开根号和外部参数\n",
    "        # print('rcs:',type(known_rcs),known_rcs)\n",
    "        if known_rcs<0:\n",
    "            known_rcs=0\n",
    "\n",
    "        return known_rcs\n",
    "\n",
    "    problem = pm.Problem(manifold=manifold, cost=cost)\n",
    "    optimizer = optimizers.SteepestDescent(max_iterations=Maxiter)\n",
    "    if Ws is None and Wt is None:\n",
    "        W = optimizer.run(problem)\n",
    "    else:\n",
    "        W = optimizer.run(problem, initial_point=[Ws[:, :dimension], Wt[:, :dimension]])\n",
    "    return W\n",
    "\n",
    "def RMI_np(FX,y,l,sigma=0.8,alpha=0.5,lamda=1e-2):\n",
    "    '''\n",
    "    FX: numpy array of feature. eg: vstack(Xs)\n",
    "    y: numpy array of labels\n",
    "    l: numpy array of domain labels\n",
    "    \n",
    "    return -->float RCS Divergence of FX,y,l\n",
    "    '''\n",
    "    m=FX.shape[0]\n",
    "    \n",
    "    Deltay=(y[:,None]==y).astype(float)\n",
    "    Deltal=(l[:,None]==l).astype(float)\n",
    "    FX_norm=anp.sum(FX**2,axis=-1)#这里由于做了归一化 所以始终都等于1 后面要考虑下要不要改\n",
    "    # print(FX_norm,FX_norm.shape)\n",
    "    # print('1',FX_norm[:,None],FX_norm[None,:])\n",
    "    # print(FX_norm[:,None].shape,FX_norm[None,:].shape)\n",
    "    A=-(FX_norm[:,None] + FX_norm[None,:])\n",
    "    # print(\"A\",A.shape)\n",
    "    B=2 * anp.dot(FX, FX.T)\n",
    "    # print(\"B\",B.shape)\n",
    "    K=anp.exp(-(FX_norm[:,None] + FX_norm[None,:] - 2 * anp.dot(FX, FX.T)) / sigma) * Deltay\n",
    "    # print('K is',K.shape)\n",
    "    P = K * Deltal\n",
    "    # print(\"P is\",P.shape)\n",
    "    H = ((1.0 - alpha) / m**2) * anp.dot(K,K) * anp.dot(Deltal,Deltal) + 1.0 * alpha / m * anp.dot(P,P)\n",
    "    h = anp.mean(P,axis=0)\n",
    "    h=h.reshape((h.shape[0],))#对齐一下向量\n",
    "\n",
    "    # theta = anp.matrix(H + lamda * anp.eye(m)).I.dot(h)\n",
    "    theta=alina.solve(H + lamda * anp.eye(m),h)\n",
    "    \n",
    "    D = 2 * anp.dot(h.T,theta)-anp.dot(theta.T,anp.dot(H,theta)) - 1\n",
    "    # print(D,type(D))\n",
    "\n",
    "    # print(H.shape,h.shape,theta.shape)\n",
    "    return D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def model_loss(Xs, Ys, Xt, Yt_pseudo, l,Cs, sigma, eta, gamma_tk, gamma_tu, gamma_s):\n",
    "    # 数据初始化\n",
    "    ms = Xs.shape[0]\n",
    "    mt = Xt.shape[0]\n",
    "    data_X = anp.vstack((Xs, Xt))\n",
    "    l_unique,l_count=np.unique(l,return_counts=True)\n",
    "    print('ms:{},mt:{}'.format(ms,mt))\n",
    "    print('lu:',l_unique,'lc',l_count)\n",
    "    # print(len(Ys),Ys)\n",
    "\n",
    "    # 初始化源域已知类的标签矩阵\n",
    "    Y0 = np.zeros([Cs + 1, ms + mt])\n",
    "    for index in range(ms):\n",
    "        # print(Ys[index],type(Ys[index]))\n",
    "        Y0[int(Ys[index]), index] = 1\n",
    "\n",
    "    # 初始化被视为未知类的标签矩阵\n",
    "    Yu = np.zeros([Cs + 1, ms + mt])\n",
    "    Yu[Cs, :] = 1\n",
    "\n",
    "    # 初始化W,V1,V2矩阵\n",
    "    W = np.zeros([ms + mt, ms + mt])\n",
    "    w1, w2 = np.diag_indices_from(W)\n",
    "    # W[w1[:ms], w2[:ms]] = np.sqrt(1 / ms)\n",
    "    \n",
    "    current_index=0\n",
    "    for i in range(len(l_unique)-1):#最后一个域是目标域 不纳入考虑\n",
    "        start=current_index\n",
    "        end=current_index+l_count[i]\n",
    "        W[w1[start:end], w2[start:end]] = np.sqrt(1 / l_count[i])\n",
    "        current_index=end\n",
    "        # print(l_count[i])\n",
    "    print('current_index',current_index)\n",
    "    # print(W)\n",
    "    \n",
    "    mtk = Yt_pseudo[Yt_pseudo < Cs].shape[0]\n",
    "    mtu = Yt_pseudo[Yt_pseudo >= Cs].shape[0]\n",
    "    V1 = np.zeros([ms + mt, ms + mt])\n",
    "    v11, v21 = np.diag_indices_from(V1)\n",
    "    V1[v11[ms:][Yt_pseudo < Cs], v21[ms:][Yt_pseudo < Cs]] = np.sqrt(1 / mtk)\n",
    "    V2 = np.zeros([ms + mt, ms + mt])\n",
    "    v12, v22 = np.diag_indices_from(V2)\n",
    "    V2[v12[ms:][Yt_pseudo >= Cs], v22[ms:][Yt_pseudo >= Cs]] = np.sqrt(1 / mtu)\n",
    "\n",
    "    # 计算特征x的核矩阵K\n",
    "    data_norm = np.sum(data_X ** 2, axis=-1)\n",
    "    pair_dist = data_norm[:, None] + data_norm[None, :] - 2 * np.dot(data_X, data_X.T)\n",
    "    K = np.exp(- pair_dist / sigma)\n",
    "\n",
    "    # 计算alpha\n",
    "    V_sub_W = gamma_tk * np.dot(V1, V1) + gamma_tu * np.dot(V2, V2) - gamma_s * np.dot(W, W)\n",
    "    alpha_l = np.dot(np.dot(W, W), K) + np.dot(V_sub_W, K) + eta * np.eye(ms + mt)\n",
    "    alpha_r = np.dot(np.dot(W, W), Y0.T) + np.dot(V_sub_W, Yu.T)\n",
    "    alpha = nlina.solve(alpha_l, alpha_r)\n",
    "    predict_alpha = np.dot(alpha.T, K)\n",
    "\n",
    "    # 计算源域损失\n",
    "    known_fro = nlina.norm(np.dot(Y0 - predict_alpha, W), ord='fro')\n",
    "    known_loss = known_fro * known_fro\n",
    "\n",
    "    # 计算被视为未知类损失\n",
    "    target_tk_fro = nlina.norm(np.dot(Yu - predict_alpha, V1), ord='fro')\n",
    "    unknown_target_tk = gamma_tk * target_tk_fro * target_tk_fro\n",
    "    target_tu_fro = nlina.norm(np.dot(Yu - predict_alpha, V2), ord='fro')\n",
    "    unknown_target_tu = gamma_tu * target_tu_fro * target_tu_fro\n",
    "    source_fro = nlina.norm(np.dot(Yu - predict_alpha, W), ord='fro')\n",
    "    unknown_source = gamma_s * source_fro * source_fro\n",
    "    unknown_loss = unknown_target_tk + unknown_target_tu - unknown_source\n",
    "\n",
    "    # 计算正则化项\n",
    "    regular_norm = eta * np.sum(np.dot(predict_alpha, alpha).diagonal())\n",
    "\n",
    "    loss = known_loss + unknown_loss + regular_norm\n",
    "    print('loss is', format(loss, '.2f'), '| known_loss is', format(known_loss, '.2f'), '| unknown_loss is',\n",
    "          format(unknown_loss, '.2f'), '(', format(unknown_target_tk, '.2f'), '+', format(unknown_target_tu, '.2f'), '-', format(unknown_source, '.2f'), ')')\n",
    "    return loss, predict_alpha,alpha\n",
    "\n",
    "def make_print_to_file(filename=\"Default.log\",path='./'):\n",
    "    '''\n",
    "    path: it is a path for save your log about fuction print\n",
    "    example:\n",
    "    use  make_print_to_file()   and the   all the information of funtion print , will be write in to a log file\n",
    "    :return:\n",
    "    '''\n",
    "    import sys\n",
    "    import os\n",
    "    import sys\n",
    "    import datetime\n",
    " \n",
    "    class Logger(object):\n",
    "        def __init__(self, filename=filename, path=\"./\"):\n",
    "            self.terminal = sys.stdout\n",
    "            self.path= os.path.join(path, filename)\n",
    "            # if not os.path.exists(self.path):\n",
    "                \n",
    "            self.log = open(self.path, \"a\", encoding='utf8',)\n",
    "            print(\"save:\", os.path.join(self.path, filename))\n",
    " \n",
    "        def write(self, message):\n",
    "            self.terminal.write(message)\n",
    "            self.log.write(message)\n",
    " \n",
    "        def flush(self):\n",
    "            pass\n",
    "    \n",
    "    print(filename)\n",
    "    fileName = filename+datetime.datetime.now().strftime('day'+'%Y_%m_%d_%H_%M')\n",
    "    sys.stdout = Logger(fileName + '.log', path=path)\n",
    " \n",
    "    #############################################################\n",
    "    # 这里输出之后的所有的输出的print 内容即将写入日志\n",
    "    #############################################################\n",
    "    print(fileName.center(60,'*'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scs=['webcam','dslr']\n",
    "tg='amazon'\n",
    "domain_num=3\n",
    "root=osp.join('Office-31_Alex','Data_office31')\n",
    "dataSet='Office31'\n",
    "\n",
    "eta=0.001\n",
    "gamma_tk=0.2\n",
    "gamma_tu=0.7\n",
    "gamma_s=0.4\n",
    "conf=-0.25\n",
    "u_conf=-0.6\n",
    "make_print_to_file(filename='{}_Mlti_2{}__proTest'.format(dataSet,tg),path='logs')\n",
    "print(\"DataSet:{}\".format(root),\"\\nTarget Domain:{}\".format(tg))\n",
    "\n",
    "Xs,ys,Xt,yt,l,Cs,Cu=readDataMS(root,scs,tg,20,21,fn='fts',postfix='_Al7')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SourceAlign(Xs,ys,l):\n",
    "    sourceNum=len(Xs)\n",
    "    \n",
    "    Xs_all=np.vstack(Xs[:-1])\n",
    "    Xs_all = scale(Xs_all, with_std=False)\n",
    "    ys_all=np.hstack(ys[:-1])\n",
    "\n",
    "    #其实都是源域 只是为了方便把一个作为目标域\n",
    "    Xt_pse=np.vstack(Xs[-1])\n",
    "    Xt_pse = scale(Xt_pse, with_std=False)\n",
    "    Yt_pse=np.hstack(ys[-1])\n",
    "    \n",
    "    np.random.seed(0)  # 使得PCA算法稳定\n",
    "    pca = PCA(svd_solver=\"full\").fit(np.vstack(Xs_all))\n",
    "    W0 = pca.components_.T  # 初始化降维矩阵为Dxd维,D＞d\n",
    "    Ws, Wt = W0, W0\n",
    "    \n",
    "    unique,index=np.unique(l,return_index=True)\n",
    "    l_source=np.array(l[:index[-1]])\n",
    "    W = cost_manifold(Ws, Wt,l_source, Cs, Xs_all, ys_all, Xt_pse, Yt_pse, 50, 100).point\n",
    "    Xs_pre = np.dot(Xs_all, W[0])\n",
    "    Xt_pre = np.dot(Xt_pse, W[1])\n",
    "    Xs_align=np.vstack([Xs_pre,Xt_pre])\n",
    "    \n",
    "    return Xs_align,W\n",
    "Xs_align,W=SourceAlign(Xs,ys,l)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对齐目标域数据\n",
    "Xt_scale = scale(Xt, with_std=False)\n",
    "Xt_align=np.dot(Xt_scale, W[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_fuc_ms(Xs, ys, Xt, Yt,Cs,Cu,conf=0):\n",
    "    # 1.加载数据\n",
    "    Xs=np.vstack(Xs)\n",
    "    ys=np.hstack(ys)\n",
    "\n",
    "    Xs = scale(Xs, with_std=False)\n",
    "    Xt = scale(Xt, with_std=False)\n",
    "\n",
    "\n",
    "    # 2.设置分类模型,标注已知类伪标签\n",
    "    Xt_label, Xt_labelConf = cla_Svc(Xs, Xt, ys)\n",
    "\n",
    "    # conf = -0.25  # 根据SVM定义,置信度大于0才属于已知类\n",
    "    Xtk = Xt[Xt_labelConf >= conf]\n",
    "    Ytk = Yt[Xt_labelConf >= conf]\n",
    "    Ytk_pseudo = Xt_label[Xt_labelConf >= conf]\n",
    "    Xtu = Xt[Xt_labelConf < conf]\n",
    "    Ytu = Yt[Xt_labelConf < conf]\n",
    "    Ytu_pseudo = Xt_label[Xt_labelConf < conf]\n",
    "    Ytu_pseudo[:] = Cs\n",
    "    \n",
    "\n",
    "    # 5.目标域数据整合\n",
    "    Xt_new = np.vstack((Xtk, Xtu))\n",
    "    Yt_new = np.hstack((Ytk, Ytu))\n",
    "    Yt_pseudo = np.hstack((Ytk_pseudo, Ytu_pseudo))\n",
    "    \n",
    "\n",
    "    \n",
    "    acc,acc_unknown,acc_known,HOS=compute_acc(Yt_new,Yt_pseudo,Cs)\n",
    "    # acc_known=compute_acc_known(Yt_new[Yt_new < Cs],Yt_pseudo[Yt_new < Cs], Cs)\n",
    "    # one_unknown=compute_one_unknown(Yt_new[Yt_new >= Cs], Yt_pseudo[Yt_new >= Cs], Cs)\n",
    "    print('all acc',acc)\n",
    "    print(\"pseudo Xtu:\", acc_unknown)\n",
    "    print(\"pseudo Xtk:\", acc_known)\n",
    "    print('HOS:',HOS)\n",
    "\n",
    "    return Xt_new,Yt_new,Yt_pseudo\n",
    "\n",
    "\n",
    "def pseudo_fuc_ms_progressive(Xs, ys, Xt, Yt,Cs,k_conf=0,u_conf=0):\n",
    "    # 1.加载数据\n",
    "    Xs=np.vstack(Xs)\n",
    "    ys=np.hstack(ys)\n",
    "    # Xs=Xs[0]\n",
    "    # ys=ys[0]\n",
    "\n",
    "    Xs = scale(Xs, with_std=False)\n",
    "    Xt = scale(Xt, with_std=False)\n",
    "\n",
    "\n",
    "    # 2.设置分类模型,标注已知类伪标签\n",
    "    Xt_label, Xt_labelConf = cla_Svc(Xs, Xt, ys)\n",
    "\n",
    "    # conf = -0.25  # 根据SVM定义,置信度大于0才属于已知类\n",
    "    Xtk = Xt[Xt_labelConf >= k_conf]\n",
    "    Ytk = Yt[Xt_labelConf >= k_conf]\n",
    "    Ytk_pseudo = Xt_label[Xt_labelConf >= k_conf]\n",
    "\n",
    "    Xtu = Xt[Xt_labelConf < u_conf]\n",
    "    Ytu = Yt[Xt_labelConf < u_conf]\n",
    "    Ytu_pseudo = Xt_label[Xt_labelConf < u_conf]\n",
    "    Ytu_pseudo[:] = Cs\n",
    "    \n",
    "\n",
    "    # 5.目标域数据整合\n",
    "    Xt_new = np.vstack((Xtk, Xtu))\n",
    "    Yt_new = np.hstack((Ytk, Ytu))\n",
    "    Yt_pseudo = np.hstack((Ytk_pseudo, Ytu_pseudo))\n",
    "\n",
    "    #未分类样本整合\n",
    "    Xt_candidate = Xt[(Xt_labelConf < k_conf) & (Xt_labelConf >= u_conf)]\n",
    "    Yt_candidate = Yt[(Xt_labelConf < k_conf) & (Xt_labelConf >= u_conf)]\n",
    "    \n",
    "    acc,acc_unknown,acc_known,HOS=compute_acc(Yt_new,Yt_pseudo,Cs)\n",
    "    # acc_known=compute_acc_known(Yt_new[Yt_new < Cs],Yt_pseudo[Yt_new < Cs], Cs)\n",
    "    # one_unknown=compute_one_unknown(Yt_new[Yt_new >= Cs], Yt_pseudo[Yt_new >= Cs], Cs)\n",
    "    print('all acc',acc)\n",
    "    print(\"pseudo Xtu:\", acc_unknown)\n",
    "    print(\"pseudo Xtk:\", acc_known)\n",
    "    print('HOS:',HOS)\n",
    "\n",
    "    return Xt_new,Yt_new,Yt_pseudo,Xt_candidate,Yt_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_new,Yt_new,Yt_pseudo=pseudo_fuc_ms(Xs_align,ys,Xt_align,yt,Cs,Cu,conf=-0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xt_new,Yt_new,Yt_pseudo=pseudo_fuc_ms(Xs,ys,Xt,yt,Cs,Cu,conf=-0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_all = scale(Xs_align, with_std=False)\n",
    "ys_all=np.hstack(ys)\n",
    "\n",
    "np.random.seed(0)  # 使得PCA算法稳定\n",
    "pca = PCA(svd_solver=\"full\").fit(np.vstack((Xs_all,Xt_new)))\n",
    "W0 = pca.components_.T  # 初始化降维矩阵为Dxd维,D＞d\n",
    "Ws, Wt = W0, W0\n",
    "# print(Ws.shape)\n",
    "accs,acc_knowns,acc_unknowns,HOSs=[],[],[],[]\n",
    "\n",
    "for i in range(8):\n",
    "    W = cost_manifold(Ws, Wt,l, Cs, Xs_all, ys_all, Xt_new, Yt_pseudo, 50, 100).point\n",
    "\n",
    "    Xs_pre = np.dot(Xs_all, W[0])\n",
    "    Xt_pre = np.dot(Xt_new, W[1])\n",
    "    \n",
    "    distance = pairwise_distances(Xs_pre, Xt_pre, 'euclidean')\n",
    "    sigma = np.median(distance[distance != 0])\n",
    "    loss, predict, alpha = model_loss(Xs_pre, ys_all , Xt_pre, Yt_pseudo, l,Cs, sigma, eta=eta, gamma_tk=gamma_tk, gamma_tu=gamma_tu, gamma_s=gamma_s)\n",
    "\n",
    "    predict_Xt = predict[:, Xs_pre.shape[0]:]  # 分类模型对目标域样本的置信度矩阵\n",
    "    predict_Xt = predict_Xt / np.sum(predict_Xt, axis=0)[None, :]  # 置信度归1\n",
    "\n",
    "    Yt_pseudo = predict_Xt.argmax(axis=0)\n",
    "\n",
    "    acc,acc_unknown,acc_known,HOS=compute_acc(Yt_new,Yt_pseudo,Cs)\n",
    "    \n",
    "    print(\"\\nIteration :{}\".format(i+1))\n",
    "    print('all acc',acc)\n",
    "    print(\"pseudo Xtu:\", acc_unknown)\n",
    "    print(\"pseudo Xtk:\", acc_known)\n",
    "    print('HOS:',HOS)  \n",
    "    accs.append(acc)\n",
    "    acc_unknowns.append(acc_unknown)\n",
    "    acc_knowns.append(acc_known)\n",
    "    HOSs.append(HOS)\n",
    "    \n",
    "print('source:{}target:{}'.format(scs,tg))\n",
    "print('eta:{}\\tgamma_tk:{}\\tgamma_tu:{}\\tgamma_s:{}\\tu_conf:{}'.format(eta,gamma_tk,gamma_tu,gamma_s,u_conf))\n",
    "for i in range(len(accs)):\n",
    "    print(\"Iterations:\",i,'\\tacc:{}\\tacc_known:{}\\tacc_unknown:{}\\tHOS:{}'.format(accs[i],acc_knowns[i],acc_unknowns[i],HOSs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_conf=-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_new,Yt_new,Yt_pseudo,Xt_candidate,Yt_candidate=pseudo_fuc_ms_progressive(Xs_align,ys,Xt_align,yt,Cs,u_conf=u_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_new,Yt_new,Yt_pseudo,Xt_candidate,Yt_candidate=pseudo_fuc_ms_progressive(Xs,ys,Xt,yt,Cs,u_conf=u_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataAssign(Xs,ys,Xt,yt,Cs,split_num=2):\n",
    "    '''\n",
    "    置信度范围是-1->1  \n",
    "    '''\n",
    "    u_conf_step=1/split_num\n",
    "    u_conf=-1+u_conf_step\n",
    "    print(u_conf)\n",
    "    Xt_new,Yt_new,Yt_pseudo,Xt_candidate,Yt_candidate=pseudo_fuc_ms_progressive(Xs,ys,Xt,yt,Cs,u_conf=u_conf)\n",
    "    Xt_new[Yt_pseudo]\n",
    "    Xt_new2=np.vstack\n",
    "    Xt_new2,Yt_new2,Yt_pseudo2=pseudo_fuc_ms(Xs,ys,Xt_candidate,Yt_candidate,Cs,Cu,conf=-0.25)\n",
    "    return [Xt_new,Xt_new2],[Yt_new,Yt_new2],[Yt_pseudo,Yt_pseudo2]\n",
    "    \n",
    "Xt_news,Yt_news,Yt_pseudos=dataAssign(Xs,ys,Xt,yt,Cs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_new,Yt_new,Yt_pseudo,Xt_candidate,Yt_candidate=pseudo_fuc_ms_progressive(Xs,ys,Xt,yt,Cs,u_conf=u_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_new,Yt_new,Yt_pseudo,Xt_candidate,Yt_candidate=pseudo_fuc_ms_progressive(Xs,ys,Xt,yt,Cs,u_conf=u_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gamma_s=[i/1000 for i in range(1,10,1)]\n",
    "Gamma_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred=[7, 19, 30, 20, 19, 8, 53, 44, 25, 59, 218]\n",
    "corret_pred=[4, 19, 28, 6, 16, 8, 19, 32, 18, 18, 154]\n",
    "total_label=[29, 21, 28, 12, 16, 31, 21, 40, 18, 19, 267]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[index/total_label[cor] for cor,index in enumerate(corret_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13793103448275862,\n",
       " 0.9047619047619048,\n",
       " 1.0,\n",
       " 0.5,\n",
       " 1.0,\n",
       " 0.25806451612903225,\n",
       " 0.9047619047619048,\n",
       " 0.8,\n",
       " 1.0,\n",
       " 0.9473684210526315,\n",
       " 0.5767790262172284]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7299697097641328"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(a)/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=[index/total_label[cor] for cor,index in enumerate(corret_pred[:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.700439718141093"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math \n",
    "math.log(26,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7452887781188232"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(k)/len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.002483443708606"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def HOS(a,b):\n",
    "    return 2*a*b/(a+b)\n",
    "HOS(55.5,65.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7561be136af4c20f61ae64066fbde9a25b93022926daecb6440711f63ea82dfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
