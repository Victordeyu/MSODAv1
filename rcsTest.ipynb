{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import scipy.linalg as la\n",
    "from sklearn.svm import SVC\n",
    "# from JDIP import JDIP\n",
    "# from MSJDIP import MSJDIP\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import scale,LabelEncoder\n",
    "from os import path as osp\n",
    "import autograd.numpy as anp\n",
    "import autograd.numpy.linalg as alina\n",
    "import pymanopt as pm\n",
    "import pymanopt.manifolds as manifolds\n",
    "import pymanopt.optimizers as optimizers\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import autograd.numpy as anp\n",
    "import autograd.numpy.linalg as alina\n",
    "import numpy as np\n",
    "import numpy.linalg as nlina\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMI_np(FX,y,l,sigma=0.8,alpha=0.5,lamda=1e-2):\n",
    "    '''\n",
    "    FX: numpy array of feature. eg: vstack(Xs)\n",
    "    y: numpy array of labels\n",
    "    l: numpy array of domain labels\n",
    "    \n",
    "    return -->float RCS Divergence of FX,y,l\n",
    "    '''\n",
    "    # print(FX)\n",
    "    m=FX.shape[0]\n",
    "    # print('m:',m)\n",
    "    \n",
    "    Deltay=(y[:,None]==y).astype(float)\n",
    "    Deltal=(l[:,None]==l).astype(float)\n",
    "    FX_norm=anp.sum(FX**2,axis=-1)#这里由于做了归一化 所以始终都等于1 后面要考虑下要不要改\n",
    "    # print(FX_norm,FX_norm.shape)\n",
    "    # print('1',FX_norm[:,None],FX_norm[None,:])\n",
    "    # print(FX_norm[:,None].shape,FX_norm[None,:].shape)\n",
    "    A=-(FX_norm[:,None] + FX_norm[None,:])\n",
    "    # print(\"A\",A.shape)\n",
    "    B=2 * anp.dot(FX, FX.T)\n",
    "    # print(\"B\",B.shape)\n",
    "    K=anp.exp(-(FX_norm[:,None] + FX_norm[None,:] - 2 * anp.dot(FX, FX.T)) / sigma) * Deltay\n",
    "    # print('K is',K.shape)\n",
    "    P = K * Deltal\n",
    "    # print(\"P is\",P.shape)\n",
    "    H = ((1.0 - alpha) / m**2) * anp.dot(K,K) * anp.dot(Deltal,Deltal) + 1.0 * alpha / m * anp.dot(P,P)\n",
    "    h = anp.mean(P,axis=0)\n",
    "    h=h.reshape((h.shape[0],))#对齐一下向量\n",
    "\n",
    "    # theta = anp.matrix(H + lamda * anp.eye(m)).I.dot(h)\n",
    "    theta=alina.solve(H + lamda * anp.eye(m),h)\n",
    "    \n",
    "    D = 2 * anp.dot(h.T,theta)-anp.dot(theta.T,anp.dot(H,theta)) - 1\n",
    "    # print(D,type(D))\n",
    "\n",
    "    # print(H.shape,h.shape,theta.shape)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataMS(root,scs,tg,Cs_end,Cu_start,fn='fea',postfix=''): \n",
    "    '''\n",
    "    root: 数据集路径,eg 'OSDA-2/Office-31_Alex/Data_office31'\n",
    "    scs: List of source domain name, eg ['dslr','webcam']\n",
    "    tg: name of target domain name, eg 'amazon'\n",
    "    Cs_end: Known end\n",
    "    Cu_start: Unknown start\n",
    "    fn: 在mat文件中feature列名 \n",
    "    postfix: 每个数据集文件的后缀名\n",
    "\n",
    "    return: \n",
    "        Xs: List of numpy array\n",
    "        Xt: Numpy array\n",
    "        l: numpy array of label of the sample\n",
    "\n",
    "    '''\n",
    "    Xs,ys,l=[],[],[]\n",
    "    li=0\n",
    "    for sc in scs:\n",
    "        data = sio.loadmat(osp.join(root ,sc + postfix+'.mat'))# source domain \n",
    "        Xsi,ysi = data[fn].astype(np.float64),data['labels'].ravel()\n",
    "        ysi = LabelEncoder().fit(ysi).transform(ysi).astype(np.float64)\n",
    "        Xsi = Xsi / la.norm(Xsi,axis=1,keepdims=True)\n",
    "        Xsn=Xsi[ysi[:]<Cs_end,:]\n",
    "        ysn=ysi[ysi[:]<Cs_end]#筛选出已知类\n",
    "        Xs.append(Xsn)\n",
    "        ys.append(ysn)\n",
    "        l=np.hstack((np.array(l),np.full((Xsn.shape[0],),li)))\n",
    "        li+=1\n",
    "\n",
    "    data = sio.loadmat(osp.join(root , tg + postfix+'.mat'))# target domain \n",
    "    Xt,yt = data[fn].astype(np.float64),data['labels'].ravel()\n",
    "    yt = LabelEncoder().fit(yt).transform(yt).astype(np.float64)\n",
    "    C=len(np.unique(yt))\n",
    "    # index_unknwon=yt[yt[:]>Cs_end and yt[:]<Cu_start]\n",
    "    print('Cu_start:',Cu_start)\n",
    "    Xt=np.vstack((Xt[yt[:]<Cs_end,:],Xt[yt[:]>=Cu_start,:]))#筛选已知类和未知类\n",
    "    yt=np.hstack((yt[yt[:]<Cs_end],yt[yt[:]>=Cu_start]))\n",
    "\n",
    "    l=np.hstack((np.array(l),np.full((Xt.shape[0],),li)))\n",
    "    \n",
    "    Xt = Xt / la.norm(Xt,axis=1,keepdims=True)\n",
    "\n",
    "    Cs = Cs_end\n",
    "    Cu = C - Cu_start\n",
    "\n",
    "    return Xs,ys,Xt,yt,l,Cs,Cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_fuc_ms(Xs, ys, Xt, Yt,Cs,Cu):\n",
    "    # 1.加载数据\n",
    "    Xs=np.vstack(Xs)\n",
    "    ys=np.hstack(ys)\n",
    "\n",
    "    Xs = scale(Xs, with_std=False)\n",
    "    Xt = scale(Xt, with_std=False)\n",
    "\n",
    "\n",
    "    # 2.设置分类模型,标注已知类伪标签\n",
    "    Xt_label, Xt_labelConf = cla_Svc(Xs, Xt, ys)\n",
    "\n",
    "    conf = 0  # 根据SVM定义,置信度大于0才属于已知类\n",
    "    Xtk = Xt[Xt_labelConf >= conf]\n",
    "    Ytk = Yt[Xt_labelConf >= conf]\n",
    "    Ytk_pseudo = Xt_label[Xt_labelConf >= conf]\n",
    "    Xtu = Xt[Xt_labelConf < conf]\n",
    "    Ytu = Yt[Xt_labelConf < conf]\n",
    "    Ytu_pseudo = Xt_label[Xt_labelConf < conf]\n",
    "    Ytu_pseudo[:] = Cs\n",
    "    # print(\"pseudo Xtk:\", compute_acc_known(Ytk, Ytk_pseudo, Cs))\n",
    "    # print(\"pseudo Xtu:\", compute_one_unknown(Ytu, Ytu_pseudo, Cs))\n",
    "    \n",
    "\n",
    "    # 5.目标域数据整合\n",
    "    Xt_new = np.vstack((Xtk, Xtu))\n",
    "    Yt_new = np.hstack((Ytk, Ytu))\n",
    "    Yt_pseudo = np.hstack((Ytk_pseudo, Ytu_pseudo))\n",
    "    # print('Yt_new',Yt_new.astype('int'))\n",
    "    # print(\"Yt_pseudo\",Yt_pseudo)\n",
    "    \n",
    "    acc,acc_unknown,acc_known=compute_acc(Yt_new,Yt_pseudo,Cs)\n",
    "    # acc_known=compute_acc_known(Yt_new[Yt_new < Cs],Yt_pseudo[Yt_new < Cs], Cs)\n",
    "    # one_unknown=compute_one_unknown(Yt_new[Yt_new >= Cs], Yt_pseudo[Yt_new >= Cs], Cs)\n",
    "    print(\"pseudo Xtk:\", acc_known)\n",
    "    print(\"pseudo Xtu:\", acc_unknown)\n",
    "    print('all acc',acc)\n",
    "        # one_acc = (acc_known * Cs + one_unknown) / (Cs + 1)\n",
    "    # 计算已知类准确率,后续应删\n",
    "    # Ytk_new = Yt_new[Yt_new < Cs]\n",
    "    # print(\"Ytk_new\",Ytk_new)\n",
    "    # Ytk_new_pseudo = Yt_pseudo[Yt_new < Cs]\n",
    "    # print(\"Ytk_new_pe\",Ytk_new_pseudo)\n",
    "    # acc_known = compute_acc_known(Ytk_new, Ytk_new_pseudo, Cs)\n",
    "    # print(\"predict Xtk :\", acc_known)\n",
    "    # # 计算未知类准确率,后续应删\n",
    "    # Ytu_new = Yt_new[Yt_new >= Cs]\n",
    "    # Ytu_new_pseudo = Yt_pseudo[Yt_new >= Cs]\n",
    "    # one_unknown = compute_one_unknown(Ytu_new, Ytu_new_pseudo, Cs)\n",
    "    # print(\"predict Xtu one :\", one_unknown)\n",
    "\n",
    "    # # 计算总体准确率\n",
    "    # one_acc = (acc_known * Cs + one_unknown) / (Cs + 1)\n",
    "    # print(\"predict Xt one:\", one_acc)\n",
    "\n",
    "    return Xt_new,Yt_new,Yt_pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cla_Svc(Xs, Xt, Ys):\n",
    "    # 2.SVM分类模型\n",
    "    model_cla = LinearSVC(dual=False)  # dual决定无法收敛时取消默认1000的迭代次数\n",
    "    model_cla.fit(Xs, Ys)\n",
    "    conf_matrix = model_cla.decision_function(Xt)\n",
    "    conf_label = conf_matrix.argmax(axis=1)  # 每个样本最大置信度的索引,即类\n",
    "    conf_vec = np.max(conf_matrix, axis=1)  # 每个样本最大置信度\n",
    "\n",
    "    return conf_label, conf_vec\n",
    "\n",
    "def compute_acc(Y, Y_pseudo, Cs):\n",
    "    acc_known = 0\n",
    "    acc_unknown = 0\n",
    "    known_i = 0\n",
    "    unknown_i = 0\n",
    "    mtk = Y[Y < Cs].shape\n",
    "    mtu = Y[Y >= Cs].shape\n",
    "    mt = Y.shape\n",
    "    # 计算已知类的分类准确率\n",
    "    for c in range(Cs):  \n",
    "        known_i += np.sum(Y_pseudo[Y == c] == Y[Y == c]) \n",
    "    acc_known = known_i/mtk\n",
    "    # 计算未知类的分类准确率\n",
    "    unknown_i = np.sum(Y_pseudo[Y >= Cs ] == Cs)\n",
    "    acc_unknown = unknown_i/mtu\n",
    "    # 计算总体分类准确率\n",
    "    acc = (unknown_i+known_i)/mt\n",
    "    print('use this')\n",
    "    return acc,acc_unknown,acc_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet:Office-31_Alex\\Data_office31 \n",
      "Target Domain:webcam\n",
      "Cu_start: 20\n",
      "use this\n",
      "pseudo Xtk: [0.84255319]\n",
      "pseudo Xtu: [0.8164794]\n",
      "all acc [0.82868526]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  5.  5.\n",
      "  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.\n",
      "  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  6.  6.  6.  6.  6.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  7.  7.  7.\n",
      "  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.\n",
      "  9. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 20. 21.\n",
      " 21. 21. 21. 21. 21. 21. 21. 21. 21. 21. 21. 21. 21. 21. 21. 21. 21. 21.\n",
      " 21. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22.\n",
      " 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 22. 23. 23. 23. 23. 23.\n",
      " 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
      " 23. 23. 23. 23. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24.\n",
      " 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24. 24.\n",
      " 24. 24. 24. 24. 24. 24. 24. 24. 25. 25. 25. 25. 25. 25. 25. 25. 25. 25.\n",
      " 25. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26. 26.\n",
      " 26. 26. 26. 26. 26. 26. 26. 26. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27.\n",
      " 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27. 27.\n",
      " 27. 27. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28. 28.\n",
      " 28. 28. 28. 28. 28. 28. 28. 28. 29. 29. 29. 29. 29. 29. 29. 29. 29. 29.\n",
      " 29. 29. 29. 29. 29. 29. 29. 29. 29. 29. 29. 29. 29. 30. 30. 30. 30. 30.\n",
      " 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30. 30.]\n"
     ]
    }
   ],
   "source": [
    "scs=['webcam','amazon']\n",
    "tg='dslr'\n",
    "root=osp.join('Office-31_Alex','Data_office31')\n",
    "\n",
    "eta=0.001\n",
    "gamma_tk=0.2\n",
    "gamma_tu=0.7\n",
    "gamma_s=0.35\n",
    "\n",
    "print(\"DataSet:{}\".format(root),\"\\nTarget Domain:{}\".format(tg))\n",
    "\n",
    "Xs,ys,Xt,yt,l,Cs,Cu=readDataMS(root,scs,tg,10,20,fn='fts',postfix='_Al7')\n",
    "\n",
    "\n",
    "Xt_new,Yt_new,Yt_pseudo=pseudo_fuc_ms(Xs,ys,Xt,yt,Cs,Cu)\n",
    "\n",
    "# print(yt)\n",
    "\n",
    "Xs_all=np.vstack(Xs)\n",
    "Xs_all = scale(Xs_all, with_std=False)\n",
    "ys_all=np.hstack(ys)\n",
    "\n",
    "np.random.seed(0)  # 使得PCA算法稳定\n",
    "pca = PCA(svd_solver=\"full\").fit(np.vstack((Xs_all,Xt)))\n",
    "W0 = pca.components_.T  # 初始化降维矩阵为Dxd维,D＞d\n",
    "Ws, Wt = W0, W0\n",
    "# print(Ws.shape)\n",
    "accs,acc_knowns,acc_unknowns=[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys,Yt=ys_all,Yt_pseudo\n",
    "Xs=Xs_all\n",
    "Xtk = Xt[Yt < Cs, :]\n",
    "Ytk = Yt[Yt < Cs]\n",
    "lk=l[np.hstack((Ys,Yt))<Cs]\n",
    "# 融合源域和目标域\n",
    "Yk_all=np.hstack((Ys,Ytk))\n",
    "Xk_all=np.vstack((Xs,Xtk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_dist = pairwise_distances(Xk_all,Xk_all, 'euclidean')**2\n",
    "known_sigma = np.median(known_dist[known_dist != 0])\n",
    "known_rcs=RMI_np(Xk_all,Yk_all,lk,sigma=known_sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_sigma:0.9485845150639364\tk_rcs:0.17373512708828942\n"
     ]
    }
   ],
   "source": [
    "print(\"k_sigma:{}\\tk_rcs:{}\".format(known_sigma,known_rcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6348\\2732241171.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0munique\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "unique,count=np.unique(lk,return_counts=True)\n",
    "unique,count=int(unique),int(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2.] [154 824 252]\n"
     ]
    }
   ],
   "source": [
    "print(unique,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RCS(x,y,lk):\n",
    "    known_dist = pairwise_distances(x,x, 'euclidean')**2\n",
    "    known_sigma = np.median(known_dist[known_dist != 0])\n",
    "    known_rcs=RMI_np(x,y,lk,alpha=0,sigma=known_sigma)\n",
    "    return known_sigma,known_rcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9438689719053157 0.4595536247491945\n"
     ]
    }
   ],
   "source": [
    "remove=0\n",
    "sigma,rcs=RCS(Xk_all[lk!=remove],Yk_all[lk!=remove],lk[lk!=remove])\n",
    "print(sigma,rcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0 for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto',init='random', perplexity=3).fit_transform(X)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_path='save_fea/pre_tar_cls.pt'\n",
    "cls=torch.load(cls_path,map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 2.0000e-04, 2.4414e-03,  ..., 6.2725e-04, 4.4940e-04,\n",
       "         3.7491e-05],\n",
       "        [1.0000e+00, 1.4230e-05, 2.3501e-05,  ..., 7.4545e-06, 1.9134e-05,\n",
       "         1.6014e-06],\n",
       "        [1.0000e+00, 6.8579e-06, 2.0717e-05,  ..., 6.5859e-06, 5.6389e-06,\n",
       "         5.4922e-07],\n",
       "        ...,\n",
       "        [8.5730e-03, 1.5260e-03, 2.7299e-03,  ..., 2.2265e-03, 9.9995e-01,\n",
       "         1.2204e-04],\n",
       "        [2.5120e-01, 4.9872e-02, 7.8490e-01,  ..., 2.5207e-01, 3.0864e-01,\n",
       "         1.2800e-02],\n",
       "        [1.7169e-01, 6.7263e-02, 2.8447e-01,  ..., 1.7237e-02, 6.5625e-01,\n",
       "         1.2359e-02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,indices=torch.max(cls,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 8, 8, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 9, 9,\n",
       "        9, 9, 3, 6, 6, 9, 6, 9, 6, 9, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 9, 6, 3, 8, 8, 6, 3, 6, 3,\n",
       "        3, 4, 6, 6, 6, 8, 3, 6, 7, 6, 7, 8, 7, 7, 8, 6, 7, 7, 6, 3, 7, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 9, 6, 6, 6, 9, 6, 9, 9, 6, 6, 9, 6, 9, 9, 6, 6,\n",
       "        9, 8, 9, 6, 3, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 8, 8, 8, 8, 8, 8, 4, 8, 4,\n",
       "        7, 2, 7, 7, 4, 7, 7, 2, 2, 7, 7, 7, 7, 8, 2, 7, 4, 2, 2, 2, 2, 4, 2, 4,\n",
       "        4, 6, 6, 6, 6, 6, 6, 6, 6, 2, 8, 8, 6, 6, 6, 6, 4, 6, 2, 8, 8, 8, 8, 8,\n",
       "        8, 6, 6, 8, 6, 6, 6, 5, 6, 5, 6, 5, 9, 6, 6, 6, 6, 6, 9, 9, 9, 9, 6, 6,\n",
       "        9, 6, 6, 6, 6, 6, 6, 4, 5, 5, 5, 6, 5, 3, 5, 9, 6, 7, 7, 6, 6, 6, 3, 7,\n",
       "        7, 8, 6, 7, 6, 5, 9, 8, 8, 8, 9, 9, 9, 9, 8, 0, 8, 9, 0, 2, 0, 9, 9, 6,\n",
       "        9, 2, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[235:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_val=values[:235]\n",
    "(k_val[k_val<0.99999]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([211])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_val=values[235:]\n",
    "(un_val[un_val<0.99999]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'day2023_09_17_15_05'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now().strftime('day'+'%Y_%m_%d_%H_%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 9, 17, 15, 5, 9, 304646)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([267])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7045)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(k_val)/k_val.shape[0]\n",
    "min(k_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9362)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(un_val)/un_val.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7561be136af4c20f61ae64066fbde9a25b93022926daecb6440711f63ea82dfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
